{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hoeffding's Inequality\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_flip_exp():\n",
    "    experiment = []\n",
    "    #generate 1000 random coins \n",
    "    for i in range(1000):\n",
    "        coin = []\n",
    "        #flip each coin ten times\n",
    "        for k in range(10):\n",
    "            #define 0 as heads, 1 as tails\n",
    "            flip = random.randint(0, 1)\n",
    "            coin.append(flip)\n",
    "        experiment.append(coin)\n",
    "    #get first coin    \n",
    "    c_1 = experiment[0]\n",
    "    #find nu for first coin\n",
    "    v_1 = sum(c_1)/10\n",
    "    #get random coin\n",
    "    random_index = np.random.choice(1000)\n",
    "    c_rand = experiment[random_index]\n",
    "    #find nu for random coin\n",
    "    v_rand = sum(c_rand)/10\n",
    "    #get minimum coin\n",
    "    c_min = min(experiment)\n",
    "    #find nu for minimum coin\n",
    "    v_min = sum(c_min)/10\n",
    "    return v_1, v_rand, v_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [36:59<00:00, 45.05it/s]\n"
     ]
    }
   ],
   "source": [
    "v1_dist = []\n",
    "vrand_dist = []\n",
    "vmin_dist = []\n",
    "#run the coin flip experiment 100,000 times and generate a distribution\n",
    "for l in tqdm(range(100000)):\n",
    "    result = coin_flip_exp()\n",
    "    v1_dist.append(result[0])\n",
    "    vrand_dist.append(result[1])\n",
    "    vmin_dist.append(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_min_avg = np.average(vmin_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04171199999999999\n"
     ]
    }
   ],
   "source": [
    "print(v_min_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.1\n",
      "0.34346\n",
      "1.6374615061559636\n",
      " satisfies Hoeffding\n",
      "0.2\n",
      "0.11111\n",
      "0.898657928234443\n",
      " satisfies Hoeffding\n",
      "0.3\n",
      "0.06684\n",
      "0.3305977764431731\n",
      " satisfies Hoeffding\n",
      "0.4\n",
      "0.00208\n",
      "0.08152440795673238\n",
      " satisfies Hoeffding\n",
      "0.5\n",
      "0.0\n",
      "0.013475893998170934\n",
      " satisfies Hoeffding\n",
      "1\n",
      "0.1\n",
      "0.34495\n",
      "1.6374615061559636\n",
      " satisfies Hoeffding\n",
      "0.2\n",
      "0.10998\n",
      "0.898657928234443\n",
      " satisfies Hoeffding\n",
      "0.3\n",
      "0.06564\n",
      "0.3305977764431731\n",
      " satisfies Hoeffding\n",
      "0.4\n",
      "0.00185\n",
      "0.08152440795673238\n",
      " satisfies Hoeffding\n",
      "0.5\n",
      "0.0\n",
      "0.013475893998170934\n",
      " satisfies Hoeffding\n",
      "2\n",
      "0.1\n",
      "1.0\n",
      "1.6374615061559636\n",
      " satisfies Hoeffding\n",
      "0.2\n",
      "0.99925\n",
      "0.898657928234443\n",
      " does not satisfy Hoeffding\n",
      "0.3\n",
      "0.9591\n",
      "0.3305977764431731\n",
      " does not satisfy Hoeffding\n",
      "0.4\n",
      "0.62453\n",
      "0.08152440795673238\n",
      " does not satisfy Hoeffding\n",
      "0.5\n",
      "0.0\n",
      "0.013475893998170934\n",
      " satisfies Hoeffding\n"
     ]
    }
   ],
   "source": [
    "#choose epsilon between 0.1 and 0.5 (reason explained in Problem 2 section)\n",
    "epsilon_possible = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "dist_list = [v1_dist, vrand_dist, vmin_dist]\n",
    "\n",
    "for b in range(3):\n",
    "    print(b) #so that we know which distribution we are checking\n",
    "    distribution = dist_list[b]\n",
    "    probability_array = []\n",
    "    #check the probability that |v-µ| > epsilon is less than or equal to 2e^-2(epsilon^2)*N\n",
    "    #check for each coin's ten flips\n",
    "    for epsilon in epsilon_possible:\n",
    "        counter = 0\n",
    "        for nu in range(100000):\n",
    "            if ((np.absolute(distribution[nu] - 0.5)) > epsilon):\n",
    "                counter += 1\n",
    "        right_hand_side = 2 * np.exp(-2 * np.square(epsilon) * 10)\n",
    "        check = counter/100000\n",
    "        print(epsilon) #so that we know for which epsilons the inequality is satisfied\n",
    "        if (check <= right_hand_side):\n",
    "            print(\" satisfies Hoeffding\")\n",
    "        else: \n",
    "            print(\" does not satisfy Hoeffding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49990299999999993\n",
      "0.500278\n"
     ]
    }
   ],
   "source": [
    "#µ = 0.5\n",
    "#which one satisifes P[v-µ > e]\n",
    "print(np.average(v1_dist))\n",
    "print(np.average(vrand_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_regression(N):\n",
    "    N = 100\n",
    "    #random coordinates chosen to use as our line\n",
    "    coordinate_one = np.random.uniform(-1, 1, 2)\n",
    "    coordinate_two = np.random.uniform(-1, 1, 2)\n",
    "\n",
    "    xN = []\n",
    "    for i in range(N): \n",
    "        #defining the first component as x0 which is always 1\n",
    "        coordinate = [1]\n",
    "        #create dataset of N random points\n",
    "        coordinate[1:2] = np.random.uniform(-1, 1, 2)\n",
    "        xN.append(coordinate)\n",
    "\n",
    "    def det_output(points, coordinate_one, coordinate_two):\n",
    "        #using the determinant to figure out whether the points lie on one side of the line or the other\n",
    "        #formula: (x-x1)(y2-y1) - (y-y1)(x2-x1) where the point is (x, y)\n",
    "        #one vector is (x-x1, y-y1), the other is (x2-x1, y2-y1) and we are taking the cross product\n",
    "        #if the point is on one side of the line, the cross product will be negative, if the point is on the other side of the line, the cross product will be positive\n",
    "        AD = (points[1] - coordinate_one[0]) * (coordinate_two[1] - coordinate_one[1])\n",
    "        BC = (points[2] - coordinate_one[1]) * (coordinate_two[0] - coordinate_one[0])\n",
    "        return np.sign(AD-BC)\n",
    "\n",
    "    outputs = []\n",
    "    for x in xN:\n",
    "        #create a list of outputs using det_output function for each point in dataset\n",
    "        sign = det_output(x, coordinate_one, coordinate_two)\n",
    "        outputs.append(int(sign))\n",
    "\n",
    "    #compute pseudo-inverse\n",
    "    xTX = np.dot(np.transpose(xN), xN)\n",
    "    pseudo = np.dot(np.linalg.inv(xTX), np.transpose(xN))\n",
    "    weights = np.dot(pseudo, outputs)\n",
    "\n",
    "    incorrect = 0\n",
    "    correct = 0\n",
    "    for j in xN:\n",
    "        #find classification using line\n",
    "        f_output = det_output(j, coordinate_one, coordinate_two)\n",
    "        #find classification using weights\n",
    "        g_output = np.sign(np.dot(weights, j))\n",
    "        #check accuracy\n",
    "        if f_output != g_output:\n",
    "            incorrect +=1\n",
    "        else:\n",
    "            correct += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_in = incorrect/(incorrect + correct)\n",
    "    \n",
    "    #generating 1000 random points for data testing\n",
    "    points_data = []\n",
    "    for i in range(1000):\n",
    "        point = [1]\n",
    "        point[1:2] = np.random.uniform(-1, 1, 2)\n",
    "        points_data.append(point)\n",
    "    incorrect = 0\n",
    "    correct = 0\n",
    "    for j in range(1000):\n",
    "        #find classification using line\n",
    "        f_output = det_output(points_data[j], coordinate_one, coordinate_two)\n",
    "        #find classification using weights\n",
    "        g_output = np.sign(np.dot(weights, points_data[j]))\n",
    "        #check accuracy\n",
    "        if f_output != g_output:\n",
    "            incorrect +=1\n",
    "        else:\n",
    "            correct += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_out = incorrect/(incorrect + correct)\n",
    "    \n",
    "    return E_in, E_out, weights, xN, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.026\n"
     ]
    }
   ],
   "source": [
    "all_E_in = []\n",
    "all_E_out = []\n",
    "for m in range(1000):\n",
    "    E_in, E_out, weights, xN, outputs = lin_regression(100)\n",
    "    all_E_in.append(E_in)\n",
    "    all_E_out.append(E_out)\n",
    "print(np.average(E_in))\n",
    "print(np.average(E_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(N, weights, xN, outputs):\n",
    "\n",
    "    #initial weight vector from linear regression\n",
    "    w = weights\n",
    "\n",
    "    iteration = 0\n",
    "    #create a list with indices of all the points that are misclassified based on the given outputs and weights from linear regression\n",
    "    misclassified = []\n",
    "    for i in range(N):\n",
    "        if np.sign(np.dot(w, xN[i])) != outputs[i]:\n",
    "            misclassified.append(i)\n",
    "    \n",
    "    #update weights\n",
    "    \n",
    "    while len(misclassified) > 0:\n",
    "        #pick a random misclassified index\n",
    "        index = random.choice(misclassified)\n",
    "        #update weight vector\n",
    "        w = w + np.dot(outputs[index], xN[index])\n",
    "        iteration += 1\n",
    "        #re-update set of misclassified points by checking whether the weight vector results \n",
    "        #in the same output\n",
    "        misclassified = []\n",
    "        for i in range(N):\n",
    "            if np.sign(np.dot(w, xN[i])) != outputs[i]:\n",
    "                misclassified.append(i)\n",
    "            \n",
    "    return iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.404\n"
     ]
    }
   ],
   "source": [
    "#input for number of points to be used\n",
    "n = 10\n",
    "iteration_total = []\n",
    "\n",
    "#run model 1000 times and take the average\n",
    "for i in range(1000):\n",
    "    E_in, E_out, weights, xN, outputs = lin_regression(n)\n",
    "    iter_val = perceptron(n, weights, xN, outputs)\n",
    "    iteration_total.append(iter_val)\n",
    "\n",
    "print(np.average(iteration_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate training set\n",
    "points_data = []\n",
    "for i in range(1000):\n",
    "    point = [1]\n",
    "    #generate points\n",
    "    point[1:2] = np.random.uniform(-1, 1, 2)\n",
    "    points_data.append(point)\n",
    "def target_function(point):\n",
    "    x1 = point[1]\n",
    "    x2 = point[2]\n",
    "    return np.sign(np.square(x1) + np.square(x2) - 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_dataset(data):\n",
    "    #create array of expected outputs\n",
    "    output = []\n",
    "    for item in data:\n",
    "        output.append(target_function(item))\n",
    "    #create noise for 10% of points\n",
    "    for m in range(100):\n",
    "        rand_point = np.random.choice(1000)\n",
    "        output[rand_point] = -1 * output[rand_point]\n",
    "    #compute pseudo-inverse\n",
    "    xTX = np.dot(np.transpose(data), data)\n",
    "    pseudo = np.dot(np.linalg.inv(xTX), np.transpose(data))\n",
    "    weights = np.dot(pseudo, output)\n",
    "\n",
    "    incorrect = 0\n",
    "    correct = 0\n",
    "    for j in data:\n",
    "        #find classification using line\n",
    "        f_output = target_function(j)\n",
    "        #find classification using weights\n",
    "        g_output = np.sign(np.dot(weights, j))\n",
    "        #check accuracy\n",
    "        if f_output != g_output:\n",
    "            incorrect +=1\n",
    "        else:\n",
    "            correct += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_in = incorrect/(incorrect + correct)\n",
    "    \n",
    "    return E_in, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:29<00:00, 33.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4821550000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "E_in_result = [] \n",
    "for a in tqdm(range(1000)):\n",
    "    E_in_result.append(lin_dataset(points_data)[0])   \n",
    "print(np.average(E_in_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:51<00:00, 19.60it/s]\n"
     ]
    }
   ],
   "source": [
    "transform_data = []\n",
    "#transform the data\n",
    "for value in points_data:\n",
    "    x1 = value[1]\n",
    "    x2 = value[2]\n",
    "    transform = [1, x1, x2, x1*x2, np.square(x1), np.square(x2)]\n",
    "    transform_data.append(transform)\n",
    "hypothesis = []\n",
    "\n",
    "for a in tqdm(range(1000)):\n",
    "    #run the linear regression on the transformed data\n",
    "    value = lin_dataset(transform_data)\n",
    "    #get final weights\n",
    "    hypothesis.append(value[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weights(hypotheses):\n",
    "    \n",
    "    weight_a = [-1, 0.05, 0.08, 0.13, 1.5, 1.5]\n",
    "    weight_b = [-1, 0.05, 0.08, 0.13, 1.5, 15]\n",
    "    weight_c = [-1, 0.05, 0.08, 0.13, 15, 1.5]\n",
    "    weight_d = [-1, 1.5, 0.08, 0.13, 0.05, 0.05]\n",
    "    weight_e = [-1, 0.05, 0.08, 1.5, .15, .15]\n",
    "    \n",
    "    given_weights = [weight_a, weight_b, weight_c, weight_d, weight_e]\n",
    "    \n",
    "    #create set of random points for testing\n",
    "    points_random = []\n",
    "    for i in range(1000):\n",
    "        point = [1]\n",
    "        #generate points\n",
    "        point[1:2] = np.random.uniform(-1, 1, 2)\n",
    "        point[3:5] = (point[1] * point[2], np.square(point[1]), np.square(point[2]))\n",
    "        points_random.append(point)\n",
    "    \n",
    "    choice_array = []\n",
    "    for choice in tqdm(given_weights):\n",
    "        for hypothesis in hypotheses:\n",
    "            #create array of expected outputs\n",
    "\n",
    "            incorrect = 0\n",
    "            correct = 0\n",
    "            for j in range(1000):\n",
    "                #find classification using found weights\n",
    "                f_output = np.sign(np.dot(hypothesis, points_random[j]))\n",
    "                #find classification using weights\n",
    "                g_output = np.sign(np.dot(choice, points_random[j]))\n",
    "                #check accuracy\n",
    "                if f_output != g_output:\n",
    "                    incorrect +=1\n",
    "                else:\n",
    "                    correct += 1\n",
    "            #calculate probability of accuracy\n",
    "            comparison = correct/(incorrect + correct)\n",
    "            all_comparisons = []\n",
    "            all_comparisons.append(comparison)\n",
    "        choice_array.append(np.average(all_comparisons))\n",
    "    \n",
    "    return choice_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:11<00:46, 11.67s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:24<00:35, 11.97s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:35<00:23, 11.78s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:48<00:11, 11.94s/it]\u001b[A\n",
      "100%|██████████| 5/5 [01:01<00:00, 12.33s/it]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "weights_comparison = check_weights(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.955, 0.669, 0.654, 0.617, 0.573]\n"
     ]
    }
   ],
   "source": [
    "print(weights_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_E_outs = []\n",
    "for hypo in hypothesis:    \n",
    "    #create set of random points for testing\n",
    "    points_set = []\n",
    "    for i in range(1000):\n",
    "        point = [1]\n",
    "        #generate points\n",
    "        point[1:2] = np.random.uniform(-1, 1, 2)\n",
    "        point[3:5] = (point[1] * point[2], np.square(point[1]), np.square(point[2]))\n",
    "        points_set.append(point)\n",
    "    f_outputs = []\n",
    "    #get outputs\n",
    "    for a in range(1000):\n",
    "        f_outputs.append(target_function(points_set[a]))\n",
    "    #add noise\n",
    "    for m in range(100):\n",
    "        rand_point = np.random.choice(1000)\n",
    "        f_outputs[rand_point] = -1 * f_outputs[rand_point]\n",
    "    incorrect = 0\n",
    "    correct = 0\n",
    "    for j in range(1000):\n",
    "        #find classification using line\n",
    "        f_output = f_outputs[j]\n",
    "        #find classification using weights\n",
    "        g_output = np.sign(np.dot(hypo, points_set[j]))\n",
    "        #check accuracy\n",
    "        if f_output != g_output:\n",
    "            incorrect +=1\n",
    "        else:\n",
    "            correct += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_out = incorrect/(incorrect + correct)\n",
    "    all_E_outs.append(E_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115274\n"
     ]
    }
   ],
   "source": [
    "print(np.average(all_E_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
