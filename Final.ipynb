{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the training files\n",
    "file = open(\"features.train.txt\", \"r\")\n",
    "lines = file.readlines()\n",
    "digits = []\n",
    "train_data = []\n",
    "#separate outputs from points\n",
    "for x in lines:\n",
    "    digits.append([float(x.split('  ')[1])])\n",
    "    #create training data with just intensity and symmetry\n",
    "    train_data.append([1, float(x.split('  ')[2]), float(x.split('  ')[3])])\n",
    "\n",
    "#read in the testing files\n",
    "test_set = open(\"features.test.txt\", \"r\")\n",
    "line = test_set.readlines()\n",
    "test_digit = []\n",
    "test_data = []\n",
    "for y in line:\n",
    "    test_digit.append([float(y.split('  ')[1])])\n",
    "    test_data.append([1, float(y.split('  ')[2]), float(y.split('  ')[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(file, digit):\n",
    "    outputs = []\n",
    "    for i in range(len(file)):\n",
    "        if float(file[i][0]) == digit:\n",
    "            outputs.append(1)\n",
    "        else:\n",
    "            outputs.append(-1)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_regular_nt(data, number, x_test):\n",
    "    output = classifier(digits, number)\n",
    "    y_test = classifier(test_digit, number)\n",
    "    #compute pseudo-inverse\n",
    "    xTX = np.dot(np.transpose(data), data)\n",
    "    add_regular = xTX + (1 * np.identity(xTX.shape[0]))\n",
    "    pseudo = np.dot(np.linalg.inv(add_regular), np.transpose(data))\n",
    "    weights = np.dot(pseudo, output)\n",
    "\n",
    "    incorrect = 0\n",
    "    correct = 0\n",
    "    for j in range(len(data)):\n",
    "        #find classification using line\n",
    "        f_output = output[j]\n",
    "        #find classification using weights\n",
    "        g_output = np.sign(np.dot(weights, data[j]))\n",
    "        #check accuracy\n",
    "        if f_output != g_output:\n",
    "            incorrect +=1\n",
    "        else:\n",
    "            correct += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_in = incorrect/(incorrect + correct)\n",
    "    \n",
    "    incorrect_test = 0\n",
    "    correct_test = 0\n",
    "    for g in range(len(x_test)):\n",
    "        #find classification using line\n",
    "        f_out = y_test[g]\n",
    "        #find classification using weights\n",
    "        g_out = np.sign(np.dot(weights, x_test[g]))\n",
    "        #check accuracy\n",
    "        if f_out != g_out:\n",
    "            incorrect_test +=1\n",
    "        else:\n",
    "            correct_test += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_out = incorrect_test/(incorrect_test + correct_test)\n",
    "    \n",
    "    return E_in, E_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [5.0, 6.0, 7.0, 8.0, 9.0]\n",
    "errors = []\n",
    "for num in classifiers:\n",
    "    errors.append(lin_regular_nt(train_data, num, test_data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  5.0\n",
      "E_in:  0.07625840076807022\n",
      "classifier:  6.0\n",
      "E_in:  0.09107118365107666\n",
      "classifier:  7.0\n",
      "E_in:  0.08846523110684405\n",
      "classifier:  8.0\n",
      "E_in:  0.07433822520916199\n",
      "classifier:  9.0\n",
      "E_in:  0.08832807570977919\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classifiers)):\n",
    "    print(\"classifier: \", classifiers[i])\n",
    "    print(\"E_in: \", errors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the points\n",
    "def transformation(point):\n",
    "    x1 = point[1]\n",
    "    x2 = point[2]\n",
    "    phi = [1, x1, x2, x1*x2, np.square(x1), np.square(x2)]\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = []\n",
    "transform_test = []\n",
    "for item in train_data:\n",
    "    transform_train.append(transformation(item))\n",
    "for val in test_data:\n",
    "    transform_test.append(transformation(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_regular(data, number, x_test):\n",
    "    output = classifier(digits, number)\n",
    "    y_test = classifier(test_digit, number)\n",
    "    #compute pseudo-inverse\n",
    "    xTX = np.dot(np.transpose(data), data)\n",
    "    add_regular = xTX + (1 * np.identity(xTX.shape[0]))\n",
    "    pseudo = np.dot(np.linalg.inv(add_regular), np.transpose(data))\n",
    "    weights = np.dot(pseudo, output)\n",
    "\n",
    "    incorrect = 0\n",
    "    correct = 0\n",
    "    for j in range(len(data)):\n",
    "        #find classification using line\n",
    "        f_output = output[j]\n",
    "        #find classification using weights\n",
    "        g_output = np.sign(np.dot(weights, data[j]))\n",
    "        #check accuracy\n",
    "        if f_output != g_output:\n",
    "            incorrect +=1\n",
    "        else:\n",
    "            correct += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_in = incorrect/(incorrect + correct)\n",
    "    \n",
    "    incorrect_test = 0\n",
    "    correct_test = 0\n",
    "    for g in range(len(x_test)):\n",
    "        #find classification using line\n",
    "        f_out = y_test[g]\n",
    "        #find classification using weights\n",
    "        g_out = np.sign(np.dot(weights, x_test[g]))\n",
    "        #check accuracy\n",
    "        if f_out != g_out:\n",
    "            incorrect_test +=1\n",
    "        else:\n",
    "            correct_test += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_out = incorrect_test/(incorrect_test + correct_test)\n",
    "    \n",
    "    return E_in, E_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [0.0, 1.0, 2.0, 3.0, 4.0]\n",
    "e_out = []\n",
    "for num in classifiers:\n",
    "    e_out.append(lin_regular(transform_train, num, transform_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  0.0\n",
      "E_out:  0.10662680617837568\n",
      "classifier:  1.0\n",
      "E_out:  0.02192326856003986\n",
      "classifier:  2.0\n",
      "E_out:  0.09865470852017937\n",
      "classifier:  3.0\n",
      "E_out:  0.08271051320378675\n",
      "classifier:  4.0\n",
      "E_out:  0.09965122072745392\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(classifiers)):\n",
    "    print(\"classifier: \", classifiers[i])\n",
    "    print(\"E_out: \", e_out[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  0.0\n",
      "E_out_NT:  0.11509715994020926\n",
      "E_out_T:  0.10662680617837568\n",
      "classifier:  1.0\n",
      "E_out_NT:  0.02242152466367713\n",
      "E_out_T:  0.02192326856003986\n",
      "classifier:  2.0\n",
      "E_out_NT:  0.09865470852017937\n",
      "E_out_T:  0.09865470852017937\n",
      "classifier:  3.0\n",
      "E_out_NT:  0.08271051320378675\n",
      "E_out_T:  0.08271051320378675\n",
      "classifier:  4.0\n",
      "E_out_NT:  0.09965122072745392\n",
      "E_out_T:  0.09965122072745392\n",
      "classifier:  5.0\n",
      "E_out_NT:  0.07972097658196313\n",
      "E_out_T:  0.07922272047832586\n",
      "classifier:  6.0\n",
      "E_out_NT:  0.08470353761833582\n",
      "E_out_T:  0.08470353761833582\n",
      "classifier:  7.0\n",
      "E_out_NT:  0.07324364723467862\n",
      "E_out_T:  0.07324364723467862\n",
      "classifier:  8.0\n",
      "E_out_NT:  0.08271051320378675\n",
      "E_out_T:  0.08271051320378675\n",
      "classifier:  9.0\n",
      "E_out_NT:  0.08819133034379671\n",
      "E_out_T:  0.08819133034379671\n"
     ]
    }
   ],
   "source": [
    "classifiers = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n",
    "e_out_transform = []\n",
    "e_out_nt = []\n",
    "for num in classifiers:\n",
    "    e_out_transform.append(lin_regular(transform_train, num, transform_test)[1])\n",
    "    e_out_nt.append(lin_regular_nt(train_data, num, test_data)[1])\n",
    "for i in range(len(classifiers)):\n",
    "    print(\"classifier: \", classifiers[i])\n",
    "    print(\"E_out_NT: \", e_out_nt[i])\n",
    "    print(\"E_out_T: \", e_out_transform[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "one_five_train = []\n",
    "for i in range(len(digits)):\n",
    "    if float(digits[i][0]) == 1:\n",
    "        outputs.append(1)\n",
    "        one_five_train.append(train_data[i])\n",
    "    if float(digits[i][0]) == 5:\n",
    "        outputs.append(-1)\n",
    "        one_five_train.append(train_data[i])\n",
    "\n",
    "test_outputs = []\n",
    "one_five_test = []\n",
    "for i in range(len(test_digit)):\n",
    "    if float(test_digit[i][0]) == 1:\n",
    "        test_outputs.append(1)\n",
    "        one_five_test.append(test_data[i])\n",
    "    if float(test_digit[i][0]) == 5:\n",
    "        test_outputs.append(-1)\n",
    "        one_five_test.append(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_five_train_T = []\n",
    "one_five_test_T = []\n",
    "for item in one_five_train:\n",
    "    one_five_train_T.append(transformation(item))\n",
    "for val in one_five_test:\n",
    "    one_five_test_T.append(transformation(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_five(data, output, x_test, y_test, l_val):\n",
    "    #compute pseudo-inverse\n",
    "    xTX = np.dot(np.transpose(data), data)\n",
    "    add_regular = xTX + (l_val * np.identity(xTX.shape[0]))\n",
    "    pseudo = np.dot(np.linalg.inv(add_regular), np.transpose(data))\n",
    "    weights = np.dot(pseudo, output)\n",
    "\n",
    "    incorrect = 0\n",
    "    correct = 0\n",
    "    for j in range(len(data)):\n",
    "        #find classification using line\n",
    "        f_output = output[j]\n",
    "        #find classification using weights\n",
    "        g_output = np.sign(np.dot(weights, data[j]))\n",
    "        #check accuracy\n",
    "        if f_output != g_output:\n",
    "            incorrect +=1\n",
    "        else:\n",
    "            correct += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_in = incorrect/(incorrect + correct)\n",
    "    \n",
    "    incorrect_test = 0\n",
    "    correct_test = 0\n",
    "    for g in range(len(x_test)):\n",
    "        #find classification using line\n",
    "        f_out = y_test[g]\n",
    "        #find classification using weights\n",
    "        g_out = np.sign(np.dot(weights, x_test[g]))\n",
    "        #check accuracy\n",
    "        if f_out != g_out:\n",
    "            incorrect_test +=1\n",
    "        else:\n",
    "            correct_test += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_out = incorrect_test/(incorrect_test + correct_test)\n",
    "    \n",
    "    return E_in, E_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_vals = [0.01, 1]\n",
    "E_in_L = []\n",
    "E_out_L = []\n",
    "for l in l_vals:\n",
    "    E_in, E_out = one_five(one_five_train_T, outputs, one_five_test_T, test_outputs, l)\n",
    "    E_in_L.append(E_in)\n",
    "    E_out_L.append(E_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda:  0.01\n",
      "E_in:  0.004484304932735426\n",
      "E_out:  0.02830188679245283\n",
      "Lambda:  1\n",
      "E_in:  0.005124919923126201\n",
      "E_out:  0.025943396226415096\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(l_vals)):\n",
    "    print(\"Lambda: \", l_vals[i])\n",
    "    print(\"E_in: \", E_in_L[i])\n",
    "    print(\"E_out: \", E_out_L[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set = [[1.0,0.0], [0.0, 1.0], [0.0, -1.0], [-1.0, 0.0], [0.0, 2.0], [0.0, -2.0], [-2.0, 0.0]]\n",
    "y_set = [-1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "def transform_z(point):\n",
    "    x1 = point[0]\n",
    "    x2 = point[1]\n",
    "    z1 = np.square(x2) - (2 * x1) - 1\n",
    "    z2 = np.square(x1) - (2 * x2) + 1\n",
    "    return [z1, z2]\n",
    "\n",
    "transform_set = []\n",
    "for p in x_set:\n",
    "    transform_set.append(transform_z(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(data, outputs):\n",
    "    #initial weight vector with all zeroed components\n",
    "    w = [0, 0, 0]\n",
    "    \n",
    "    xN = []\n",
    "    for x_val in data:\n",
    "        x1 = x_val[0]\n",
    "        x2 = x_val[1]\n",
    "        xN.append([1, x1, x2])\n",
    "    \n",
    "    iteration = 0\n",
    "    #all points are misclassified to begin with. create a list with indices of all the points\n",
    "    misclassified = list(range(len(xN)))\n",
    "    while len(misclassified) > 0:\n",
    "        #pick a random misclassified index\n",
    "        index = random.choice(misclassified)\n",
    "        #update weight vector\n",
    "        w = w + np.dot(outputs[index], xN[index])\n",
    "        #if there are no misclassified points remaining, exit while loop\n",
    "        if misclassified ==[]:\n",
    "            update == True\n",
    "        #re-update set of misclassified points by checking whether the weight vector results \n",
    "        #in the same output\n",
    "        misclassified = []\n",
    "        for i in range(len(xN)):\n",
    "            if np.sign(np.dot(w, xN[i])) != outputs[i]:\n",
    "                misclassified.append(i)\n",
    "                \n",
    "    return w, xN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, xN = perceptron(transform_set, y_set)\n",
    "\n",
    "b = w[0]\n",
    "weight = w[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.linalg.norm(np.dot(np.transpose(w), xN[0]))\n",
    "w_norm = w/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.dot(np.transpose(w), xN[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "1.4142135623730951\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = [-1, 1]\n",
    "b = [1, -1]\n",
    "c = [1, 0]\n",
    "d = [0, 1]\n",
    "for val in [a, b, c, d]:\n",
    "    print(np.linalg.norm(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm((np.dot(b, transform_set[1]) - 0.5))\n",
    "np.linalg.norm((np.dot(a, transform_set[3]) - 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Kernel Matrix\n",
    "y_matrix = np.zeros((7, 7))\n",
    "for i in range(len(y_set)):\n",
    "    for j in range(len(y_set)):\n",
    "        y_matrix[i][j] = y_set[i] * y_set[j]\n",
    "ker = sklearn.metrics.pairwise.polynomial_kernel(x_set, gamma = 1, coef0 = 1, degree = 2)\n",
    "ker_matrix = np.multiply(y_matrix, ker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.69e+15]\n",
      "[ 2.28e+00]\n",
      "[ 6.76e+15]\n",
      "[ 5.07e+15]\n",
      "[-8.44e+14]\n",
      "[ 2.53e+15]\n",
      "[-1.69e+15]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "P = ker_matrix\n",
    "q = np.ones((1, ker_matrix.shape[0]))\n",
    "\n",
    "y_set_a = np.zeros((1, 7))\n",
    "for i in range(7):\n",
    "    y_set_a[0][i] = y_set[i]\n",
    "\n",
    "sol = cvxopt.solvers.qp(P = cvxopt.matrix(P), q = cvxopt.matrix(-np.transpose(q)), G = None, h = None, A = cvxopt.matrix((y_set_a)),\n",
    "                  b = cvxopt.matrix(0.0))\n",
    "print(sol['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0., -1.],\n",
       "       [-1.,  0.],\n",
       "       [ 0.,  2.],\n",
       "       [ 0., -2.]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(C=float(\"inf\"), kernel='poly', degree = 2, coef0 = 1, gamma = 1)\n",
    "model.fit(x_set, y_set).support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(point):\n",
    "    x1 = point[1]\n",
    "    x2 = point[2]\n",
    "    return np.sign(x2 - x1 + (0.25 * np.sin(np.pi * x1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_in = []\n",
    "\n",
    "for i in range(10000): \n",
    "    training_points = []\n",
    "    out = []\n",
    "    for a in range(100):\n",
    "        coordinate = [1]\n",
    "        #create dataset of N random points\n",
    "        coordinate[1:2] = np.random.uniform(-1, 1, 2)\n",
    "        training_points.append(coordinate)\n",
    "    for p in training_points:\n",
    "        out.append(target_func(p))\n",
    "\n",
    "    #define hard-margin by setting a large C value\n",
    "    model = svm.SVC(C = float(\"inf\"), kernel='rbf', gamma = 1.5)\n",
    "    E_in.append(1 - model.fit(training_points, out).score(training_points, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for error in E_in:\n",
    "    if error > 0.0:\n",
    "        num +=1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lloyds(k, gam):   \n",
    "    kmeans = cluster.KMeans(n_clusters = k)\n",
    "    training_points = []\n",
    "    out = []\n",
    "    for a in range(100):\n",
    "        coordinate = [1]\n",
    "        #create dataset of N random points\n",
    "        coordinate[1:2] = np.random.uniform(-1, 1, 2)\n",
    "        training_points.append(coordinate)\n",
    "    for p in training_points:\n",
    "        out.append(target_func(p))\n",
    "    lloyd = kmeans.fit(training_points)\n",
    "    if len(lloyd.cluster_centers_) == 0:\n",
    "        return\n",
    "    phi = sklearn.metrics.pairwise.rbf_kernel(training_points, lloyd.cluster_centers_, gamma = gam)\n",
    "\n",
    "    xTX = np.dot(np.transpose(phi), phi)\n",
    "    pseudo = np.dot(np.linalg.inv(xTX), np.transpose(phi))\n",
    "    weights = np.dot(pseudo, out)\n",
    "    \n",
    "    #Create set of points for testing\n",
    "    test_points = []\n",
    "    test_out = []\n",
    "    for a in range(100):\n",
    "        coordinate = [1]\n",
    "        #create dataset of N random points\n",
    "        coordinate[1:2] = np.random.uniform(-1, 1, 2)\n",
    "        test_points.append(coordinate)\n",
    "    for p in test_points:\n",
    "        test_out.append(target_func(p))\n",
    "    \n",
    "    #Find E_out\n",
    "    incorrect_test = 0\n",
    "    correct_test = 0\n",
    "    test_phi = sklearn.metrics.pairwise.rbf_kernel(test_points, lloyd.cluster_centers_, gamma = 1.5)\n",
    "    g_output = np.sign(np.dot(test_phi, weights))\n",
    "    for g in range(len(test_points)):\n",
    "        #find classification using line\n",
    "        f_out = test_out[g]\n",
    "        #find classification using weights\n",
    "        g_out = g_output[g]\n",
    "        #check accuracy\n",
    "        if f_out != g_out:\n",
    "            incorrect_test +=1\n",
    "        else:\n",
    "            correct_test += 1\n",
    "    #calculate probability of accuracy\n",
    "    E_out_reg = incorrect_test/(incorrect_test + correct_test)\n",
    "    \n",
    "    #Find E_in\n",
    "    incorr_in = 0\n",
    "    corr_in = 0\n",
    "    g_output_in = np.sign(np.dot(phi, weights))\n",
    "    for g in range(len(training_points)):\n",
    "        #find classification using line\n",
    "        f_out = out[g]\n",
    "        #find classification using weights\n",
    "        g_out = g_output_in[g]\n",
    "        #check accuracy\n",
    "        if f_out != g_out:\n",
    "            incorr_in +=1\n",
    "        else:\n",
    "            corr_in += 1\n",
    "    E_in_reg = incorr_in/(incorr_in + corr_in)\n",
    "    \n",
    "    '''ker_model = svm.SVC(C = float(\"inf\"), kernel='rbf', gamma = 1.5)\n",
    "    E_out_ker = (1 - (ker_model.fit(training_points, out).score(test_points, test_out)))\n",
    "    \n",
    "    if E_out_ker==0.0:\n",
    "        return 2\n",
    "    \n",
    "    if E_out_ker < E_out_reg:\n",
    "        to_return = 1\n",
    "    else:\n",
    "        to_return = 0'''\n",
    "    \n",
    "    return E_out_reg, E_in_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7794432548179872\n"
     ]
    }
   ],
   "source": [
    "lloyd_E = []\n",
    "for a in (range(500)):\n",
    "    lloyd_E.append(lloyds(9, 1.5))\n",
    "filtered=[i for i in lloyd_E if i<2]\n",
    "print(sum(filtered)/len(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6390658174097664\n"
     ]
    }
   ],
   "source": [
    "lloyd_E = []\n",
    "for a in (range(500)):\n",
    "    lloyd_E.append(lloyds(12, 1.5))\n",
    "filtered=[i for i in lloyd_E if i<2]\n",
    "print(sum(filtered)/len(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in Most Often:  -1\n",
      "E_out Most Oftern:  -1\n"
     ]
    }
   ],
   "source": [
    "lloyd_E_in = []\n",
    "lloyd_E_out = []\n",
    "for a in (range(500)):\n",
    "    E_o_9, E_i_9 = (lloyds(9, 1.5))\n",
    "    E_o_12, E_i_12 = (lloyds(12, 1.5))\n",
    "    \n",
    "    if E_i_9 < E_i_12:\n",
    "        lloyd_E_in.append(1) # 1 = goes up\n",
    "    if E_i_9 > E_i_12:\n",
    "        lloyd_E_in.append(-1) # -1 = goes down\n",
    "    if E_i_9 == E_i_12:\n",
    "        lloyd_E_in.append(0) # 0 = same\n",
    "        \n",
    "    if E_o_9 < E_o_12:\n",
    "        lloyd_E_out.append(1) # 1 = goes up\n",
    "    if E_o_9 > E_o_12:\n",
    "        lloyd_E_out.append(-1) # -1 = goes down\n",
    "    if E_o_9 == E_o_12:\n",
    "        lloyd_E_out.append(0) # 0 = same\n",
    "\n",
    "print(\"E_in Most Often: \", st.mode(lloyd_E_in))\n",
    "print(\"E_out Most Oftern: \", st.mode(lloyd_E_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in Most Often:  1\n",
      "E_out Most Oftern:  -1\n"
     ]
    }
   ],
   "source": [
    "lloyd_E_in = []\n",
    "lloyd_E_out = []\n",
    "for a in (range(500)):\n",
    "    E_o_1, E_i_1 = (lloyds(9, 1.5))\n",
    "    E_o_2, E_i_2 = (lloyds(9, 2))\n",
    "    \n",
    "    if E_i_1 < E_i_2:\n",
    "        lloyd_E_in.append(1) # 1 = goes up\n",
    "    if E_i_1 > E_i_2:\n",
    "        lloyd_E_in.append(-1) # -1 = goes down\n",
    "    if E_i_1 == E_i_2:\n",
    "        lloyd_E_in.append(0) # 0 = same\n",
    "        \n",
    "    if E_o_1 < E_o_2:\n",
    "        lloyd_E_out.append(1) # 1 = goes up\n",
    "    if E_o_1 > E_o_2:\n",
    "        lloyd_E_out.append(-1) # -1 = goes down\n",
    "    if E_o_1 == E_o_2:\n",
    "        lloyd_E_out.append(0) # 0 = same\n",
    "\n",
    "print(\"E_in Most Often: \", st.mode(lloyd_E_in))\n",
    "print(\"E_out Most Oftern: \", st.mode(lloyd_E_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018\n"
     ]
    }
   ],
   "source": [
    "lloyd_E = []\n",
    "for a in (range(1000)):\n",
    "    lloyd_E.append(lloyds(9, 1.5)[1])\n",
    "print(lloyd_E.count(0)/len(lloyd_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
