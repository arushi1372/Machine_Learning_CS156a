{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(N):\n",
    "    #random coordinates chosen to use as our line\n",
    "    coordinate_one = np.random.uniform(-1, 1, 2)\n",
    "    coordinate_two = np.random.uniform(-1, 1, 2)\n",
    "\n",
    "    xN = []\n",
    "    for i in range(N): \n",
    "        #defining the first component as x0 which is always 1\n",
    "        coordinate = [1]\n",
    "        #create dataset of N random points\n",
    "        coordinate[1:2] = np.random.uniform(-1, 1, 2)\n",
    "        xN.append(coordinate)\n",
    "\n",
    "    def det_output(points, coordinate_one, coordinate_two):\n",
    "        #using the determinant to figure out whether the points lie on one side of the line or the other\n",
    "        #formula: (x-x1)(y2-y1) - (y-y1)(x2-x1) where the point is (x, y)\n",
    "        AD = (points[1] - coordinate_one[0]) * (coordinate_two[1] - coordinate_one[1])\n",
    "        BC = (points[2] - coordinate_one[1]) * (coordinate_two[0] - coordinate_one[0])\n",
    "        return np.sign(AD-BC)\n",
    "\n",
    "    outputs = []\n",
    "    for x in xN:\n",
    "        #create a list of outputs using det_output function for each point in dataset\n",
    "        sign = det_output(x, coordinate_one, coordinate_two)\n",
    "        outputs.append(int(sign))\n",
    "\n",
    "    #initial weight vector with all zeroed components\n",
    "    w = [0, 0, 0]\n",
    "\n",
    "    iteration = 0\n",
    "    #all points are misclassified to begin with. create a list with indices of all the points\n",
    "    misclassified = list(range(N))\n",
    "    while len(misclassified) > 0:\n",
    "        #pick a random misclassified index\n",
    "        index = random.choice(misclassified)\n",
    "        #update weight vector\n",
    "        w = w + np.dot(outputs[index], xN[index])\n",
    "        iteration += 1\n",
    "        #if there are no misclassified points remaining, exit while loop\n",
    "        if misclassified ==[]:\n",
    "            update == True\n",
    "        #re-update set of misclassified points by checking whether the weight vector results \n",
    "        #in the same output\n",
    "        misclassified = []\n",
    "        for i in range(N):\n",
    "            if np.sign(np.dot(w, xN[i])) != outputs[i]:\n",
    "                misclassified.append(i)\n",
    "    \n",
    "    #testing with random points\n",
    "    points_data = []\n",
    "    for i in range(1000):\n",
    "        point = [1]\n",
    "        #generate points\n",
    "        point[1:2] = np.random.uniform(-1, 1, 2)\n",
    "        points_data.append(point)\n",
    "    incorrect = 0\n",
    "    correct = 0\n",
    "    for j in range(1000):\n",
    "        #find classification using line\n",
    "        f_output = det_output(points_data[j], coordinate_one, coordinate_two)\n",
    "        #find classification using weights\n",
    "        g_output = np.sign(np.dot(w, points_data[j]))\n",
    "        #check accuracy\n",
    "        if f_output != g_output:\n",
    "            incorrect +=1\n",
    "        else:\n",
    "            correct += 1\n",
    "    #calculate probability of accuracy\n",
    "    probability = incorrect/(incorrect + correct)\n",
    "            \n",
    "    return iteration, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.814\n",
      "0.013108000000000002\n"
     ]
    }
   ],
   "source": [
    "iteration_total = []\n",
    "probability_avg = []\n",
    "#input for number of points to be used\n",
    "n = 100\n",
    "#run model 1000 times and take the average\n",
    "for i in range(1000):\n",
    "    iter_val = perceptron(n)[0]\n",
    "    probability = perceptron(n)[1]\n",
    "    iteration_total.append(iter_val)\n",
    "    probability_avg.append(probability)\n",
    "\n",
    "print(np.average(iteration_total))\n",
    "print(np.average(probability_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
